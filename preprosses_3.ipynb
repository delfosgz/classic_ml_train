{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePandasPreprocessor(mlflow.pyfunc.PythonModel):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 raw_categorical_cols_config, raw_numerical_cols_config, \n",
    "                 date_col_config, premium_col_config, interactions_base_col_config, # Base cols for FE\n",
    "                 label_col_config, # Used only for TE fitting\n",
    "                 te_smoothing_config, \n",
    "                 cat_impute_const_config, num_impute_strat_config):\n",
    "        \n",
    "        # Store configurations passed during instantiation\n",
    "        self.raw_cat_cols = list(raw_categorical_cols_config)\n",
    "        self.raw_num_cols = list(raw_numerical_cols_config)\n",
    "        self.date_col = date_col_config\n",
    "        self.premium_col = premium_col_config\n",
    "        self.interactions_base_col = interactions_base_col_config # e.g., \"past_interactions_count\"\n",
    "        \n",
    "        self.label_col_for_te = label_col_config \n",
    "        self.te_smoothing = te_smoothing_factor\n",
    "        self.cat_impute_val = cat_impute_constant\n",
    "        self.num_impute_strat = num_impute_strategy\n",
    "\n",
    "        # These will be populated by the fit method\n",
    "        self.fitted_num_imputer = None\n",
    "        self.fitted_cat_imputer = None\n",
    "        self.fitted_target_encoder = None\n",
    "        self.fitted_scaler = None\n",
    "        self.final_feature_names_in_order = [] # Critical: defines output features and their order\n",
    "        self.impute_medians_for_final_features = {} # For imputing NaNs before scaling in transform\n",
    "\n",
    "    def _apply_user_custom_formatting(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Placeholder for user's initial custom data formatting.\"\"\"\n",
    "        print(\"    Executing Step 0: Initial Custom Formatting (User to define logic)...\")\n",
    "        # !!! REPLACE THIS WITH YOUR CUSTOM DATAFRAME CLEANING/FORMATTING LOGIC !!!\n",
    "        # Example: df_formatted = df.rename(columns={'old_name': 'new_name'})\n",
    "        # Ensure this function returns a DataFrame.\n",
    "        # Columns in self.raw_cat_cols and self.raw_num_cols should exist after this.\n",
    "        df_formatted = df.copy() \n",
    "        # Add your logic here, e.g.:\n",
    "        # if 'some_column_to_clean' in df_formatted.columns:\n",
    "        #     df_formatted['some_column_to_clean'] = df_formatted['some_column_to_clean'].str.lower()\n",
    "        return df_formatted\n",
    "\n",
    "    def _engineer_base_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str], List[str]]:\n",
    "        \"\"\"Creates basic engineered features from raw ones.\"\"\"\n",
    "        print(\"    Executing Step 1: Base Feature Engineering...\")\n",
    "        df_eng = df.copy()\n",
    "        new_cat_features, new_num_features = [], []\n",
    "\n",
    "        # Date features\n",
    "        if self.date_col and self.date_col in df_eng.columns:\n",
    "            try:\n",
    "                s_date = pd.to_datetime(df_eng[self.date_col], errors='coerce')\n",
    "                if not s_date.isnull().all():\n",
    "                    df_eng['fe_month'] = s_date.dt.month.astype(str)\n",
    "                    df_eng['fe_day_of_week'] = s_date.dt.dayofweek.astype(str)\n",
    "                    new_cat_features.extend(['fe_month', 'fe_day_of_week'])\n",
    "            except Exception as e: print(f\"      Warning: Date FE failed for {self.date_col}: {e}\")\n",
    "\n",
    "        # Premium transformations\n",
    "        if self.premium_col and self.premium_col in df_eng.columns:\n",
    "            prem_num = pd.to_numeric(df_eng[self.premium_col], errors='coerce')\n",
    "            df_eng['fe_log1p_premium'] = np.log1p(prem_num.fillna(0).clip(lower=0))\n",
    "            df_eng['fe_sq_premium'] = prem_num.fillna(0)**2\n",
    "            new_num_features.extend(['fe_log1p_premium', 'fe_sq_premium'])\n",
    "        \n",
    "        # Example: Log transform for another numeric interactions base column\n",
    "        if self.interactions_base_col and self.interactions_base_col in df_eng.columns:\n",
    "            inter_num = pd.to_numeric(df_eng[self.interactions_base_col], errors='coerce')\n",
    "            df_eng[f'fe_log1p_{self.interactions_base_col}'] = np.log1p(inter_num.fillna(0).clip(lower=0))\n",
    "            new_num_features.append(f'fe_log1p_{self.interactions_base_col}')\n",
    "            \n",
    "        print(f\"      Created new categoricals: {new_cat_features}\")\n",
    "        print(f\"      Created new numericals: {new_num_features}\")\n",
    "        return df_eng, new_cat_features, new_num_features\n",
    "\n",
    "    def _engineer_interaction_features(self, df: pd.DataFrame, target_encoded_cols: List[str]) -> Tuple[pd.DataFrame, List[str]]:\n",
    "        \"\"\"Creates interaction features, typically post-target encoding.\"\"\"\n",
    "        print(\"    Executing Step 4: Interaction Feature Engineering...\")\n",
    "        df_interact = df.copy()\n",
    "        new_interaction_features = []\n",
    "\n",
    "        # Use log_premium if created, else original premium\n",
    "        premium_for_interact = f'fe_log1p_{self.premium_col}' if f'fe_log1p_{self.premium_col}' in df_interact.columns else self.premium_col\n",
    "        \n",
    "        if premium_for_interact not in df_interact.columns:\n",
    "            print(\"      Warning: Premium column for interaction not found. Skipping interactions.\")\n",
    "            return df_interact, []\n",
    "        \n",
    "        # Ensure premium column is numeric for multiplication\n",
    "        df_interact[premium_for_interact] = pd.to_numeric(df_interact[premium_for_interact], errors='coerce').fillna(0)\n",
    "\n",
    "        # Interact premium with (now numeric) target-encoded categoricals\n",
    "        for te_col in target_encoded_cols: # te_cols are the original categorical names, now holding numeric TE values\n",
    "            if te_col in df_interact.columns: # Should always be true\n",
    "                interact_col_name = f\"fe_inter_{premium_for_interact}_x_{te_col}\"\n",
    "                # Ensure te_col is numeric (it should be after TargetEncoder)\n",
    "                df_interact[te_col] = pd.to_numeric(df_interact[te_col], errors='coerce').fillna(0)\n",
    "                df_interact[interact_col_name] = df_interact[premium_for_interact] * df_interact[te_col]\n",
    "                new_interaction_features.append(interact_col_name)\n",
    "                print(f\"      Created interaction: {interact_col_name}\")\n",
    "        \n",
    "        print(f\"      Created new interactions: {new_interaction_features}\")\n",
    "        return df_interact, new_interaction_features\n",
    "\n",
    "    def fit(self, train_pdf_raw_features: pd.DataFrame, train_y_series: pd.Series):\n",
    "        \"\"\"Fits all preprocessing steps.\"\"\"\n",
    "        print(\"  Fitting SimplePandasPreprocessor...\")\n",
    "        \n",
    "        # Step 0: User's Custom Initial Formatting\n",
    "        df_custom_formatted = self._apply_user_custom_formatting(train_pdf_raw_features)\n",
    "\n",
    "        # Step 1: Base Feature Engineering\n",
    "        df_fe, eng_cat_cols, eng_num_cols = self._engineer_base_features(df_custom_formatted)\n",
    "        \n",
    "        # Define all numerical and categorical columns post-base FE\n",
    "        current_numerical_cols = list(set(self._get_valid_cols(df_fe, self.raw_num_cols) + eng_num_cols))\n",
    "        current_categorical_cols = list(set(self._get_valid_cols(df_fe, self.raw_cat_cols) + eng_cat_cols))\n",
    "        \n",
    "        # Step 2a: Impute Numerical Features\n",
    "        if current_numerical_cols:\n",
    "            num_imputer = SimpleImputer(strategy=self.num_impute_strat)\n",
    "            df_fe[current_numerical_cols] = num_imputer.fit_transform(df_fe[current_numerical_cols])\n",
    "            self.fitted_components['numerical_imputer'] = num_imputer\n",
    "            self.fitted_components['imputed_numerical_cols'] = current_numerical_cols\n",
    "        else: self.fitted_components['imputed_numerical_cols'] = []\n",
    "        \n",
    "        # Step 2b: Impute Categorical Features\n",
    "        if current_categorical_cols:\n",
    "            cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=self.cat_impute_val)\n",
    "            df_fe[current_categorical_cols] = cat_imputer.fit_transform(df_fe[current_categorical_cols])\n",
    "            self.fitted_components['categorical_imputer'] = cat_imputer\n",
    "            self.fitted_components['imputed_categorical_cols'] = current_categorical_cols\n",
    "        else: self.fitted_components['imputed_categorical_cols'] = []\n",
    "\n",
    "        # Step 3: Target Encode Categoricals\n",
    "        # Uses imputed categorical columns\n",
    "        target_encoded_cols_list = []\n",
    "        cols_to_te = self.fitted_components.get('imputed_categorical_cols', [])\n",
    "        if cols_to_te:\n",
    "            for col in cols_to_te: df_fe[col] = df_fe[col].astype('category')\n",
    "            target_encoder = ce.TargetEncoder(\n",
    "                cols=cols_to_te, smoothing=self.te_smoothing, \n",
    "                handle_unknown='value', handle_missing='value'\n",
    "            )\n",
    "            # TargetEncoder modifies specified columns in place when fit_transform is used on a subset\n",
    "            df_fe_te_transformed_subset = target_encoder.fit_transform(df_fe[cols_to_te], train_y_series)\n",
    "            for col in cols_to_te: # Update the main df\n",
    "                df_fe[col] = df_fe_te_transformed_subset[col]\n",
    "\n",
    "            self.fitted_components['target_encoder'] = target_encoder\n",
    "            target_encoded_cols_list = list(cols_to_te) # These are now numeric\n",
    "            self.fitted_components['target_encoded_cols_list'] = target_encoded_cols_list # Store original names of TE'd cols\n",
    "        else: self.fitted_components['target_encoded_cols_list'] = []\n",
    "        \n",
    "        # Step 4: Interaction Feature Engineering (Post-TE)\n",
    "        df_interactions, engineered_interaction_cols_list = self._engineer_interaction_features(df_fe, target_encoded_cols_list)\n",
    "        self.fitted_components['engineered_interaction_cols_list'] = engineered_interaction_cols_list\n",
    "        \n",
    "        # Step 5: Scaling - Define final feature set for scaling\n",
    "        # This includes: original numerics (imputed), base engineered numerics (imputed), \n",
    "        # target-encoded categoricals (now numeric), and interaction features (numeric).\n",
    "        self.final_feature_columns_in_order = list(set(\n",
    "            self.fitted_components.get('imputed_numerical_cols', []) +\n",
    "            self.fitted_components.get('target_encoded_cols_list', []) + \n",
    "            self.fitted_components.get('engineered_interaction_cols_list', [])\n",
    "        ))\n",
    "        # Ensure consistent order (e.g., sorted)\n",
    "        self.final_feature_columns_in_order.sort() \n",
    "        self.fitted_components['final_feature_columns_in_order'] = self.final_feature_columns_in_order\n",
    "\n",
    "        # Final imputation pass before scaling for any NaNs created by TE 'value' or interactions\n",
    "        if self.final_feature_columns_in_order:\n",
    "            temp_final_impute_medians = {}\n",
    "            for col in self.final_feature_columns_in_order:\n",
    "                # Ensure column exists and is numeric, if not, problem upstream\n",
    "                if col not in df_interactions.columns: \n",
    "                    print(f\"    Warning: Column '{col}' expected for scaling not found. Creating as 0.\"); df_interactions[col] = 0\n",
    "                df_interactions[col] = pd.to_numeric(df_interactions[col], errors='coerce')\n",
    "                if df_interactions[col].isnull().any():\n",
    "                    median_val = df_interactions[col].median()\n",
    "                    df_interactions[col] = df_interactions[col].fillna(median_val)\n",
    "                    temp_final_impute_medians[col] = median_val\n",
    "            if temp_final_impute_medians:\n",
    "                self.fitted_components['impute_medians_for_final_features'] = temp_final_impute_medians\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            df_interactions[self.final_feature_columns_in_order] = scaler.fit_transform(df_interactions[self.final_feature_columns_in_order])\n",
    "            self.fitted_components['scaler'] = scaler\n",
    "            print(f\"    Fitted StandardScaler on {len(self.final_feature_columns_in_order)} final features.\")\n",
    "        else:\n",
    "            print(\"    No final features to scale.\")\n",
    "        \n",
    "        print(\"  SimplePandasPreprocessor fitting complete.\")\n",
    "        return self # Return self with fitted components\n",
    "\n",
    "    def transform(self, df_raw_features: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Applies all fitted transformations to new raw feature data.\"\"\"\n",
    "        print(f\"  Transforming data with SimplePandasPreprocessor (input shape {df_raw_features.shape})...\")\n",
    "        if not self.fitted_components or not self.final_feature_columns_in_order:\n",
    "            raise RuntimeError(\"Preprocessor has not been fitted. Call fit() first.\")\n",
    "\n",
    "        df_custom = self._apply_user_custom_formatting(df_raw_features.copy())\n",
    "        df_fe = self._engineer_base_features(df_custom) # Don't pass is_fitting_phase\n",
    "\n",
    "        # Impute Numerical\n",
    "        imputed_num_cols = self.fitted_components.get('imputed_numerical_cols', [])\n",
    "        valid_num_cols = self._get_valid_cols(df_fe, imputed_num_cols)\n",
    "        if valid_num_cols and self.fitted_components.get('numerical_imputer'):\n",
    "            df_fe[valid_num_cols] = self.fitted_components['numerical_imputer'].transform(df_fe[valid_num_cols])\n",
    "\n",
    "        # Impute Categorical\n",
    "        imputed_cat_cols = self.fitted_components.get('imputed_categorical_cols', [])\n",
    "        valid_cat_cols = self._get_valid_cols(df_fe, imputed_cat_cols)\n",
    "        if valid_cat_cols and self.fitted_components.get('categorical_imputer'):\n",
    "            df_fe[valid_cat_cols] = self.fitted_components['categorical_imputer'].transform(df_fe[valid_cat_cols])\n",
    "        \n",
    "        # Target Encode\n",
    "        te_cols = self.fitted_components.get('target_encoded_cols_list', [])\n",
    "        valid_te_cols = self._get_valid_cols(df_fe, te_cols)\n",
    "        if valid_te_cols and self.fitted_components.get('target_encoder'):\n",
    "            for col in valid_te_cols: df_fe[col] = df_fe[col].astype('category')\n",
    "            # TargetEncoder's transform only needs X\n",
    "            transformed_te_subset = self.fitted_components['target_encoder'].transform(df_fe[valid_te_cols])\n",
    "            for col in valid_te_cols: # Update main dataframe\n",
    "                df_fe[col] = transformed_te_subset[col]\n",
    "        \n",
    "        # Interaction Features\n",
    "        df_interactions, _ = self._engineer_interaction_features(df_fe, is_fitting_phase=False)\n",
    "        \n",
    "        # Final Imputation and Scaling\n",
    "        # Create a DataFrame with only the final_feature_columns_in_order, handling missing ones\n",
    "        df_for_scaling = pd.DataFrame(index=df_interactions.index)\n",
    "        final_impute_medians = self.fitted_components.get('impute_medians_for_final_features', {})\n",
    "        for col in self.final_feature_columns_in_order:\n",
    "            if col in df_interactions.columns:\n",
    "                df_for_scaling[col] = pd.to_numeric(df_interactions[col], errors='coerce')\n",
    "                if df_for_scaling[col].isnull().any(): # Impute if NaNs present\n",
    "                    df_for_scaling[col] = df_for_scaling[col].fillna(final_impute_medians.get(col, 0)) # Use learned median or 0\n",
    "            else: # Column expected by scaler is missing\n",
    "                print(f\"    Warning: Feature column '{col}' for scaling not found in input. Creating as 0 for scaling.\")\n",
    "                df_for_scaling[col] = 0 # Or some other default\n",
    "        \n",
    "        if self.final_feature_columns_in_order and self.fitted_components.get('scaler'):\n",
    "            # Ensure df_for_scaling only has columns in final_feature_columns_in_order before transform\n",
    "            df_for_scaling_ordered = df_for_scaling[self.final_feature_columns_in_order]\n",
    "            scaled_values = self.fitted_components['scaler'].transform(df_for_scaling_ordered)\n",
    "            df_processed = pd.DataFrame(scaled_values, columns=self.final_feature_columns_in_order, index=df_for_scaling_ordered.index)\n",
    "        elif self.final_feature_columns_in_order: # Scaler not fitted, but return features in order\n",
    "            df_processed = df_for_scaling[self.final_feature_columns_in_order]\n",
    "            print(\"    Warning: Scaler not fitted/found. Returning features before scaling but in final order.\")\n",
    "        else: # No final features defined\n",
    "            print(\"    Warning: No final features defined for preprocessor. Returning empty DataFrame.\")\n",
    "            df_processed = pd.DataFrame(index=df_raw_features.index)\n",
    "\n",
    "        print(f\"  Transformation complete. Output shape: {df_processed.shape}\")\n",
    "        return df_processed"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
